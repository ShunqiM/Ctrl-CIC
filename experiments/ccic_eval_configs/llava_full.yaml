recursive_load_config: True  # recursive load all "_default.yaml" files (from current level to all upper-level folders)

use_cached_feature: False
save_model_output: False
use_image_embs: True

# extra_special_tokens: [<MSK>, <SEP>, <CPT>]

use_clip_score: False
use_sent_score: False
use_local_model: False

evaluator:
  callable: SimpleEvaluator
  params:
    run_id: zeroshot-llava
    max_steps: 1000000
    # max_steps: 262144
    per_device_eval_batch_size: 1
    remove_unused_columns: False
    dataloader_num_workers: 16
    # output_dir: tmp
    output_dir: ${CKPT}/CIC/experiments
    # output_dir: ${CKPT}/CIC/test
    fp16: True
    eval_steps: 0
    do_val: False
    do_test: True
    test_model_index: 0
    save_model_output: False
    ccic_model: 'zeroshot'
    debug: False
    wandb: False
    load_predictions: False


dataset:
  validset:
    callable: CCICInferenceDataset
    params:
      csv_name: val_image_dict_v7.csv
      feature_matrix_name: val_image_feature_matrix.pt
      max_src_len: 511
      max_tgt_len: 128
      mask_dir: 't5-large_mean_512'
      normalise_score: fix_scale
      mask_threshold: 0.65
      pad_image: True

  testset:
    callable: CCICInferenceDataset
    params:
      csv_name: test_image_dict_ccic_fullset_v1.csv


      feature_matrix_name: test_image_feature_matrix.pt
      max_src_len: 511
      max_tgt_len: 128
      mask_dir: 't5-large_mean_512'
      normalise_score: fix_scale
      mask_threshold: 0.65
      ccic_json_path: sample_1_highlight_1_fullset.json
      

      mode: 'zeroshot'
      pad_image: True
      # return_highlight_sents: True
      debug: False
      # return_clip_image: True
  # testset:
  #   callable: Web2MMaskPrefixDataset
  #   params:
  #     csv_name: test_image_dict_v7.csv
  #     feature_matrix_name: test_image_dict_v7.pt
  #     max_src_len: 511
  #     max_tgt_len: 128
  #     mask_dir: 't5-large_mean_512'
  #     normalise_score: fix_scale
  #     mask_threshold: 0.65
  #     extract_sentence: True
  #     max_extract_len: 255
  #     return_prefix: False
  #     pad_image: True
      
model:
  model_class: transformers.LlavaForConditionalGeneration
  callable: Llava
  params:
    pretrained_model_name_or_path: liuhaotian/llava-v1.6-mistral-7b
    pretrained_model_name_or_path: llava-hf/llava-1.5-7b-hf
    
    # torch_dtype: torch.float16
    device_map: "auto"

# model:
# model_class: transformers.LongT5ForConditionalGeneration
# callable: LongT5
# params:
#   pretrained_model_name_or_path: google/long-t5-tglobal-base